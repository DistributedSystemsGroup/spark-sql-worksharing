This section describes how cache primitives can be applied to the context of work-sharing in large-scale distributed computing engines. The optimization process contains 4 phases and is described in Figure \ref{fig:phases_mqo}. Queries submitted by multiple users are parsed, analyzed and individually optimized by the query optimizer in traditional way. Our optimization process starts with the optimized logical plan (the optimized operator tree) of each query as the input. In this paper, we use the term \emph{logical plan} as the logical representation of a query. The (optimized) logical plans are sent to a central server where our optimizations are applied.
\begin{figure}[!htb]
	\centering
 	\includegraphics[scale=0.7]{figures/phases_mqo}
   	\caption{Proposed architecture.} 
   	\label{fig:phases_mqo}
\end{figure}

\textbf{Phase 1: Similar subExpressions(SEs) identification}\\
The goal of this phase is to quickly identify all potential sharing opportunities - the Similar Subexpressions (SEs). We compute an \emph{operator fingerprint} for each operator in each logical plan and store it in a fingerprint table. If two operators (and its descendants) have the same fingerprint then we call them similar subexpressions. We will discuss this technique in Section \ref{sec:common_sub}. Found similar subexpressions represents the potential candidates for building covering subexpressions (CEs) in the next phase.

\textbf{Phase 2: Building Covering SubExpressions}\\
Given the sets of SEs, the optimizer first tries to eliminate bad candidates for sharing with the help of cardinality and cost estimation. In this phase, some heuristics are applied to quickly reduce the solution space. Then for each set of SEs, we construct a CE that covers the computation of those expressions. Some CEs are dependent on other CEs, thus CEs are put into groups (classes).

\textbf{Phase 3: Cost-based optimization}\\
This phase achieves the objective of selecting the best combination of CEs which then become \emph{cache plans}, taking into account the memory constraints and the cost of the caching operation. By using our cost estimation, each CE in previous phase will be assigned a weight and a profit. Finding the best \emph{cache plans} is the most important materialization of our idea to achieve high performance work sharing. We model the challenge such that solving it is equal to solving the Multiple Choice Knapsack problem.

\textbf{Phase 4: Query rewriting}\\
Finally, the input queries are rewritten in which the cache plans are employed. This step involves some query transformations on the original queries.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Common subexpression identification}
\label{sec:common_sub}
\input{common_sub}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Building Covering SubExpression}
\label{sec:covering_subexpression}
\input{covering_subexpression}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Cost-based optimization}
\label{sec:cbo}
\input{cbo}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Query Rewriting}
\label{sec:query_rewriting}
\input{query_rewriting}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We next cover in detail the implementation of our system running on Apache Spark and Spark SQL.